% --- CLASE SOBERANA: IEEEtran ---
% 'journal' = Formato de revista (doble columna, denso).
% 'compsoc' = Optimizado para computación/ingeniería.
\documentclass[journal, compsoc, 12pt]{IEEEtran}

% --- IDIOMA Y FUENTE ---
\usepackage[utf8]{inputenc}
\usepackage[spanish, es-tabla]{babel} % 'es-tabla' usa "Tabla" en lugar de "Cuadro"
\usepackage{libertinus} % La mejor fuente del mundo mundial
\usepackage[T1]{fontenc}
\usepackage{microtype}  % Micro-ajustes tipográficos esenciales para doble columna
\usepackage{csquotes}

% --- ARSENAL DE CITACIÓN(Vancouver/Numérico) ---
% IEEE usa citas numéricas [1], ideal para esto.
\usepackage[backend=biber, style=ieee, sorting=none]{biblatex}
\addbibresource{referencias.bib}

% --- UTILIDADES ---
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath} % Para tus ecuaciones de señales
\usepackage{booktabs} % Para tablas profesionales
\usepackage[colorlinks=true, linkcolor=black, citecolor=black, urlcolor=blue]{hyperref}

% --- METADATOS DEL PAPER ---
\title{Análisis de Señales para la Detección de Patologías en Voz: Proyecto Cordectomía}

% En IEEE, los autores se ponen en un bloque especial
\author{Alfonso~Gamboa~Rubén, \\ Flores Monteros Edsel Yetlanezi% <- Este % evita espacios extra
\thanks{Documento entregado el dia: \today. Trabajo realizado para la materia de Análisis de Señales, Universidad Veracruzana.}}

% ==========================================================
%                  INICIO DEL PAPER
% ==========================================================
\begin{document}

% Crea el título que abarca ambas columnas
\maketitle

% --- RESUMEN (Abstract) ---
% En formato IEEE, el resumen va en negrita y al inicio.
\begin{abstract}
  La cordectomía, procedimiento quirúrgico que implica la extirpación parcial o total de los pliegues vocales, compromete severamente la capacidad comunicativa del paciente, afectando su identidad y calidad de vida. Este proyecto presenta el diseño y evaluación de un sistema de procesamiento digital de señales (DSP) orientado a la rehabilitación vocal no invasiva mediante la reconstrucción espectral. La metodología evolucionó a través de tres fases iterativas: una aproximación inicial en el dominio de la frecuencia (FFT global), un modelo adaptativo basado en metadatos y filtrado de intensidad adaptable, y finalmente, la implementación basada en la Transformada de Fourier de Tiempo Corto (STFT) y estimadores estadísticos (MMSE-STSA). Los resultados experimentales demostraron que, si bien la sustracción de ruido estacionario mediante algoritmos de Wiener y Ephraim-Malah es efectiva, la reconstrucción de la voz requiere una intervención más compleja a nivel de las micro-características que forman la voz para lograr preservar la identidad del paciente y evitar artefactos o distorsiones. El estudio concluye proponiendo una versión adicional de experimentación modular que implementa herramientas de inteligencia artificial.
  % --- PALABRAS CLAVE ---
  \begin{IEEEkeywords}
    Procesamiento Digital de Señales (DSP), Transformada de Fourier de Tiempo Corto (STFT), Filtro de Wiener, Filtro Savitzky-Golay, Detección de Actividad de Voz (VAD), Análisis Espectral, Rehabilitación Fónica, Python, Cordectomía, Ephraim-Malah, Formantes, Inteligencia Artificial (IA), RLHF, Red Neuronal, Speech Emotion Recognition (SER).
  \end{IEEEkeywords}

  \subsection*{Objetivo General}
    Desarrollar y evaluar algoritmos de procesamiento digital de señales basado en análisis espectral de tiempo corto y modelado estadístico, en relación a la capacidad de mejorar la calidad de la voz y restaurar parcialmente las características tímbricas en grabaciones de voz de pacientes sometidos a cordectomía.

    \subsubsection*{Objetivos Específicos}
  \begin{enumerate}
    \item \textbf{Caracterización Acústica:} Construir una base de datos pareada (pre y post-operatoria) para identificar los patrones de pérdida armónica y deformación espectral en el dominio de la frecuencia causados por la intervención quirúrgica.
    \item \textbf{Optimización de la Relación Señal-Ruido (SNR):} Implementar y comparar técnicas de sustracción espectral (Noisereduce vs. Ephraim-Malah/VAD) para minimizar el ruido estacionario inherente a la fonación soplada sin degradar los transitorios de la voz.
    \item \textbf{Reconstrucción Espectral:} Experimentar con algoritmos de transferencia de características que utilicen una máscara espectral diferencial ($T_{dB}$) para proyectar el timbre e identidad del sonido vocal (envolvente de frecuencia de la voz) sano sobre la señal patológica.
    \item \textbf{Validación Técnica:} Evaluar mediante espectrogramas y gráficas comparativas, la efectividad de los algoritmos en la rehabilitación de formantes y reducción de artefactos y desfase de frecuencias armónicas.
  \end{enumerate}

\end{abstract}

\selectlanguage{english}
\newpage

\begin{abstract}
  Cordectomy, a surgical procedure involving partial or total removal of vocal folds, severely compromises communicative capacity and patient identity. This project presents the design and evaluation of a digital signal processing (DSP) system for non-invasive vocal rehabilitation via spectral reconstruction. The methodology evolved through three iterative phases: an initial frequency domain approach (global FFT), an adaptive model based on metadata, and finally, an implementation based on Short-Time Fourier Transform (STFT) with statistical estimators (MMSE-STSA). Experimental results showed that while stationary noise subtraction via Wiener and Ephraim-Malah algorithms is effective, voice reconstruction requires complex intervention at the micro-feature level to preserve patient identity and avoid artifacts. The study concludes by proposing a future modular version implementing artificial intelligence tools.
  % --- PALABRAS CLAVE ---s
  \begin{IEEEkeywords}
    Procesamiento Digital de Señales (DSP), Transformada de Fourier de Tiempo Corto (STFT), Filtro de Wiener, Filtro Savitzky-Golay, Detección de Actividad de Voz (VAD), Análisis Espectral, Rehabilitación Fónica, Python, Cordectomía, Ephraim-Malah, Formantes, Inteligencia Artificial (IA), RLHF, Red Neuronal, Speech Emotion Recognition (SER).
  \end{IEEEkeywords}
\end{abstract}
\selectlanguage{spanish}


\newpage

\section{Introducción}
\IEEEPARstart{L}alo

\section{Metodología}


% --- REFERENCIAS ---
\begin{thebibliography}{99}

\bibitem{ref1} T. E. Oliphant, "A guide to NumPy," USA: Trelgol Publishing, vol. 1, 2006.
\bibitem{ref2} W. McKinney, "Python for data analysis: Data wrangling with Pandas, NumPy, and IPython," O'Reilly Media, Inc., 2012.
\bibitem{ref3} S. van der Walt, S. C. Colbert, and G. Varoquaux, "The NumPy array: A structure for efficient numerical computation," \textit{Computing in Science \& Engineering}, vol. 13, no. 2, pp. 22-30, 2011.
\bibitem{ref4} J. M. Kizza, "Python for scientific computing," in \textit{Guide to Computer Network Security}, Springer, 2017, pp. 263-283.
\bibitem{ref5} P. Virtanen et al., "SciPy 1.0: fundamental algorithms for scientific computing in Python," \textit{Nature Methods}, vol. 17, no. 3, pp. 261-272, 2020.
\bibitem{ref6} E. Jones, T. Oliphant, and P. Peterson, "SciPy: Open source scientific tools for Python," 2001.
\bibitem{ref7} A. Savitzky and M. J. E. Golay, "Smoothing and differentiation of data by simplified least squares procedures," \textit{Analytical Chemistry}, vol. 36, no. 8, pp. 1627-1639, 1964.
\bibitem{ref8} R. W. Schafer, "What is a Savitzky-Golay filter? [lecture notes]," \textit{IEEE Signal Processing Magazine}, vol. 28, no. 4, pp. 111-117, 2011.
\bibitem{ref9} W. H. Press and S. A. Teukolsky, "Savitzky-Golay smoothing filters," \textit{Computers in Physics}, vol. 4, no. 6, pp. 669-672, 1990.
\bibitem{ref10} M. Schmid, D. Rath, and U. Diebold, "Why and how Savitzky–Golay filters should be replaced," \textit{ACS Measurement Science Au}, vol. 2, no. 2, pp. 185-196, 2022.
\bibitem{ref11} H. H. Madden, "Comments on the Savitzky-Golay convolution method for least-squares-fit smoothing and differentiation of digital data," \textit{Analytical Chemistry}, vol. 50, no. 9, pp. 1383-1386, 1978.
\bibitem{ref12} J. O. Smith, "Spectral audio signal processing," W3K Publishing, 2011.
\bibitem{ref13} L. R. Rabiner and B. Gold, "Theory and application of digital signal processing," Englewood Cliffs, NJ: Prentice-Hall, Inc., 1975.
\bibitem{ref14} J. B. Allen and L. R. Rabiner, "A unified approach to short-time Fourier analysis and synthesis," \textit{Proceedings of the IEEE}, vol. 65, no. 11, pp. 1558-1564, 1977.
\bibitem{ref15} M. R. Portnoff, "Time-frequency representation of digital signals and systems based on short-time Fourier analysis," \textit{IEEE Transactions on Acoustics, Speech, and Signal Processing}, vol. 28, no. 1, pp. 55-69, 1980.
\bibitem{ref16} M. Dolson, "The phase vocoder: A tutorial," \textit{Computer Music Journal}, vol. 10, no. 4, pp. 14-27, 1986.
\bibitem{ref17} D. Griffin and J. Lim, "Signal estimation from modified short-time Fourier transform," \textit{IEEE Transactions on Acoustics, Speech, and Signal Processing}, vol. 32, no. 2, pp. 236-243, 1984.
\bibitem{ref18} B. Sharpe, "Invertibility of overlap-add processing," https://gauss256.github.io/blog/cola.html, accessed July 2019.
\bibitem{ref19} L. R. Rabiner and R. W. Schafer, "Digital processing of speech signals," Englewood Cliffs, NJ: Prentice Hall, 1978.
\bibitem{ref20} Y. Ephraim and D. Malah, "Speech enhancement using a minimum-mean square error short-time spectral amplitude estimator," \textit{IEEE Transactions on Acoustics, Speech, and Signal Processing}, vol. 32, no. 6, pp. 1109-1121, 1984.
\bibitem{ref21} N. Wiener, "Extrapolation, interpolation, and smoothing of stationary time series: with engineering applications," MIT Press, 1949.
\bibitem{ref22} J. Chen, J. Benesty, Y. Huang, and S. Doclo, "New insights into the noise reduction Wiener filter," \textit{IEEE Transactions on Audio, Speech, and Language Processing}, vol. 14, no. 4, pp. 1218-1234, 2006.
\bibitem{ref23} P. C. Loizou, "Speech enhancement: theory and practice," CRC Press, 2013.
\bibitem{ref24} S. F. Boll, "Suppression of acoustic noise in speech using spectral subtraction," \textit{IEEE Transactions on Acoustics, Speech, and Signal Processing}, vol. 27, no. 2, pp. 113-120, 1979.
\bibitem{ref25} J. Sohn, N. S. Kim, and W. Sung, "A statistical model-based voice activity detection," \textit{IEEE Signal Processing Letters}, vol. 6, no. 1, pp. 1-3, 1999.
\bibitem{ref26} A. J. M. Houtsma, "Pitch and timbre: Definition, meaning and use," \textit{Journal of New Music Research}, vol. 26, no. 2, pp. 104-115, 1997.
\bibitem{ref27} H. M. Teager and S. M. Teager, "Evidence for nonlinear sound production mechanisms in the vocal tract," in \textit{Speech Production and Speech Modelling}, Springer, 1990, pp. 241-261.
\bibitem{ref28} P. Ladefoged, "Vowels and consonants: An introduction to the sounds of languages," Malden, MA: Blackwell Publishers, 2001.
\bibitem{ref29} G. Fant, "Acoustic theory of speech production," The Hague: Mouton, 1960.
\bibitem{ref30} G. E. Peterson and H. L. Barney, "Control methods used in a study of the vowels," \textit{The Journal of the Acoustical Society of America}, vol. 24, no. 2, pp. 175-184, 1952.
\bibitem{ref31} J. Hillenbrand, L. A. Getty, M. J. Clark, and K. Wheeler, "Acoustic characteristics of American English vowels," \textit{The Journal of the Acoustical Society of America}, vol. 97, no. 5, pp. 3099-3111, 1995.
\bibitem{ref32} K. N. Stevens, "Acoustic phonetics," MIT Press, 1998.
\bibitem{ref33} D. H. Whalen and A. G. Levitt, "The universality of intrinsic F0 of vowels," \textit{Journal of Phonetics}, vol. 23, no. 3, pp. 349-366, 1995.
\bibitem{ref34} I. R. Titze, "Principles of voice production," Iowa City: National Center for Voice and Speech, 2000.
\bibitem{ref35} M. Hirano, "Clinical examination of voice," Springer Science \& Business Media, 2013.
\bibitem{ref36} C. E. Silver et al., "Current trends in initial management of laryngeal cancer," \textit{European Archives of Oto-Rhino-Laryngology}, vol. 266, no. 9, pp. 1333-1352, 2009.
\bibitem{ref37} M. Remacle et al., "Endoscopic cordectomy. A proposal for a classification," \textit{European Archives of Oto-Rhino-Laryngology}, vol. 257, no. 4, pp. 227-231, 2000.
\bibitem{ref38} E. V. Sjögren et al., "Voice outcome in T1a midcord glottic carcinoma," \textit{Archives of Otolaryngology–Head \& Neck Surgery}, vol. 134, no. 9, pp. 965-972, 2008.
\bibitem{ref39} T. Yılmaz et al., "Voice after cordectomy type I or type II or radiation therapy," \textit{Otolaryngology–Head and Neck Surgery}, vol. 168, no. 3, pp. 559-568, 2023.
\bibitem{ref40} L. M. Aaltonen et al., "Voice quality after treatment of early vocal cord cancer," \textit{International Journal of Radiation Oncology Biology Physics}, vol. 90, no. 2, pp. 255-270, 2014.
\bibitem{ref41} H. S. Lee et al., "Voice outcome according to surgical extent of transoral laser microsurgery," \textit{The Laryngoscope}, vol. 126, no. 9, pp. 2051-2056, 2016.
\bibitem{ref42} A. K. Fouad et al., "Laryngeal compensation for voice production after CO2 laser cordectomy," \textit{Clinical and Experimental Otorhinolaryngology}, vol. 8, no. 4, pp. 340-346, 2015.
\bibitem{ref43} G. Fant, "Acoustic theory of speech production: with calculations based on X-ray studies," The Hague: Mouton, 1960.
\bibitem{ref44} T. Chiba and M. Kajiyama, "The vowel: Its nature and structure," Tokyo-Kaiseikan Publishing Co., 1941.
\bibitem{ref45} K. N. Stevens, "Acoustic phonetics," Current Studies in Linguistics Series, vol. 30, MIT Press, 1999.
\bibitem{ref46} J. L. Flanagan, "Speech analysis synthesis and perception," Berlin: Springer-Verlag, 1972.
\bibitem{ref47} I. R. Titze, "Nonlinear source-filter coupling in phonation: Theory," \textit{The Journal of the Acoustical Society of America}, vol. 123, no. 5, pp. 2733-2749, 2008.
\bibitem{ref48} P. Birkholz, D. Jackèl, and B. J. Kröger, "Construction and control of a three-dimensional vocal tract model," in \textit{2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings}, IEEE, vol. 1, 2006.
\bibitem{ref49} B. H. Story, "A parametric model of the vocal tract area function," \textit{The Journal of the Acoustical Society of America}, vol. 117, no. 5, pp. 3231-3254, 2005.
\bibitem{ref50} W. J. Hardcastle, J. Laver, and F. E. Gibbon, \textit{The Handbook of Phonetic Sciences}, 2nd ed. Oxford: Wiley-Blackwell, 2010.
\bibitem{ref51} I. Goodfellow, Y. Bengio, y A. Courville, \textit{Deep Learning}. MIT Press, 2016.
\bibitem{ref52} J. Wang, K. Chin, y H. Wang, "Speaker-informed speech enhancement and separation," en \textit{Proc. IEEE Intl. Conf. on Acoustics, Speech and Signal Processing (ICASSP)}, 2021.
\bibitem{ref53} Y. Fathullah et al., "Neural Speech Synthesis using Semantic Tokens," \textit{arXiv preprint arXiv:2305.xxxx}, 2023.
\bibitem{ref54} W.-N. Hsu et al., "HuBERT: Self-Supervised Speech Representation Learning," en \textit{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, vol. 29, pp. 3451-3460, 2021.
\bibitem{ref55} K. Qian et al., "ContentVec: An Improved Self-Supervised Speech Representation," en \textit{Proc. of the 39th International Conference on Machine Learning (ICML)}, 2022.
\bibitem{ref56} N. Tishby y N. Zaslavsky, "Deep learning and the information bottleneck principle," en \textit{IEEE Information Theory Workshop (ITW)}, 2015.
\bibitem{ref57} X. Tan et al., "A Survey on Neural Speech Synthesis," \textit{arXiv preprint arXiv:2106.15561}, 2021.
\bibitem{ref58} RVC-Project, "Retrieval-based Voice Conversion WebUI," GitHub repository, 2023.
\bibitem{ref59} C. Kavin (svc-develop-team), "So-VITS-SVC: SoftVC VITS Singing Voice Conversion," GitHub repository, 2023.
\bibitem{ref60} E. Gölge et al., "Coqui XTTS: Open-Source Text-to-Speech Model," Coqui AI, 2023.
\bibitem{ref61} A. Radford et al., "Robust Speech Recognition via Large-Scale Weak Supervision," \textit{OpenAI Technical Report}, 2022.
\bibitem{ref62} J. Kong, J. Kim, y J. Bae, "HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis," en \textit{Proc. NeurIPS}, 2020.
\bibitem{ref63} P. Christiano et al., "Deep Reinforcement Learning from Human Feedback," \textit{Advances in Neural Information Processing Systems}, 2017.
\bibitem{ref64} R. A. Khalil et al., "Speech Emotion Recognition Using Deep Learning Techniques: A Review," \textit{IEEE Access}, vol. 7, pp. 117327-117345, 2019.

\end{thebibliography}


\end{document}
